```Java
Properties properties = new Properties();
// 配置名称可见 ConsumerConfig
properties.put("bootstrap.servers", "kafkaIP:PORT"); // 配置服务器 IP:PORT，多个用逗号隔开  
properties.put("group.id", "consumer_group_1"); // 消费者组ID
properties.put("enable.auto.commit", "true"); // 开启自动提交，默认值就是 true
properties.put("auto.commit.interval.ms", "1000"); // 默认 5s，自动提交的超时时限
properties.put("session.timeout.ms", "30000"); // 默认 10s，消费者需要向 broker 发送心跳。这里指定 broker 未收到心跳，判定该消费者宕机的时限
properties.put("heartbeat.interval.ms", "10000"); // 默认 3s，消费者的心跳间隔
properties.put("max.poll.records", "500"); // 一次 poll 最多消费多少条消息，如果是自动提交这些消息应该在自动提交时限内消费完毕
// 没有指定 offset 或者指定的 offset 无效时，从哪里开始消费
// earliest 最早的 offset  
// latest 最后的 offset
// none 或 anything else 抛出异常
properties.put("auto.offset.reset", "earliest"); 
// 配置 key value 反序列化器  
properties.put("key.deserializer", "org.apache.kafka.common.serialization.IntegerDeserializer");
properties.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

KafkaConsumer<Integer,String> consumer = new KafkaConsumer<>(properties);

// 订阅主题  

consumer.subscribe(Collections.singletonList("topic1"));

// 消费，消息等待时间  1000ms，超时后仍没有消息则返回空
ConsumerRecords<Integer, String> records = consumer.poll(1000);
for(ConsumerRecord record : records){
    records.topic();
    records.partition();
    records.key();
    records.value();
}

// 自动提交有可能出现重复消费问题  
// 所以一般配置成手动提交  
// 手动提交又分为三种 
// 同步提交，提交失败会重试，收到 broker 响应前会阻塞，影响消费者吞吐量  
consumer.commitSync();
// 异步提交，不会进行重试，收到 broker 响应前不用阻塞
// 不进行重试提交，是因为重试可能导致后提交的位移比先提交的位移大，造成位移覆盖导致重复消费  
// 偶尔出现失败也不会影响消费，因为后续的提交最终会将这次失败的 offset 给提交掉
// 使用异步提交会出现重复消费问题：Broker 接收到提交前宕机，触发 reblance 导致未提交的消息重复消费
consumer.commitAsync( (offsets, exception) -> {
    if(exception != null){
        // sout("提交失败");
    }
});
// 同异步联合提交：异步提交失败后进行同步提交，提交之前不会继续消费，避免重复消费
consuer.commitAsync( (offsets, exception) -> {
    if(exception != null){
        // sout("提交失败");
        consumer.commitSync();
    }
});
```

[back](../7.md)  